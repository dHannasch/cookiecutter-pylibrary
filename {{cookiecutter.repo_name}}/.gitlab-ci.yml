image: dahanna/python:alpine-miniconda-3.7-git-tox

{% if cookiecutter.docs_require_package == 'yes' -%}
stages:
  - buildimage
  - pages
  - build
  - test

{% endif -%}

# https://docs.gitlab.com/ee/ci/yaml/includes.html#re-using-a-before_script-template
include:
  - local: '.before_script.yml'

.build_with_kaniko:
  #Hidden job to use as an "extends" template
  only:
    variables:
      - $BUILD_DOCKER_IMAGE != null
  image:
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [""]
{%- if cookiecutter.docs_require_package == 'yes' %}
  stage: buildimage
{%- else %}
  stage: build
{%- endif %}
  script:
    - echo "Building and shipping image to $CI_REGISTRY_IMAGE"
      #Build date for opencontainers
    - BUILDDATE="'$(date '+%FT%T%z' | sed -E -n 's/(\+[0-9]{2})([0-9]{2})$/\1:\2/p')'" #rfc 3339 date
    - IMAGE_LABELS="$IMAGE_LABELS --label org.opencontainers.image.created=$BUILDDATE --label build-date=$BUILDDATE"
      #Description for opencontainers
    - BUILDTITLE=$(echo $CI_PROJECT_TITLE | tr " " "_")
    - IMAGE_LABELS="$IMAGE_LABELS --label org.opencontainers.image.title=$BUILDTITLE --label org.opencontainers.image.description=$BUILDTITLE"
      #Add ref.name for opencontainers
    - IMAGE_LABELS="$IMAGE_LABELS --label org.opencontainers.image.ref.name=$CI_REGISTRY_IMAGE:$CI_COMMIT_REF_NAME"
      #Build Version Label and Tag from git tag, LastVersionTagInGit was placed by a previous job artifact
    - if [[ "$VERSIONLABELMETHOD" == "LastVersionTagInGit" ]]; then VERSIONLABEL=$(cat VERSIONTAG.txt); fi
    - if [[ "$VERSIONLABELMETHOD" == "OnlyIfThisCommitHasVersion" ]]; then VERSIONLABEL=$CI_COMMIT_TAG; fi
    - | 
      if [[ ! -z "$VERSIONLABEL" ]]; then 
        IMAGE_LABELS="$IMAGE_LABELS --label org.opencontainers.image.version=$VERSIONLABEL"
        ADDITIONALTAGLIST="$ADDITIONALTAGLIST $VERSIONLABEL"
      fi
    - ADDITIONALTAGLIST="$ADDITIONALTAGLIST $CI_COMMIT_REF_NAME $CI_COMMIT_SHORT_SHA"
    - if [[ "$CI_COMMIT_BRANCH" == "$CI_DEFAULT_BRANCH" ]]; then ADDITIONALTAGLIST="$ADDITIONALTAGLIST latest"; fi
    - | 
      if [[ -n "$ADDITIONALTAGLIST" ]]; then 
        for TAG in $ADDITIONALTAGLIST; do 
          FORMATTEDTAGLIST="${FORMATTEDTAGLIST} --tag $CI_REGISTRY_IMAGE:$TAG "; 
        done; 
      fi
      #Reformat Docker tags to kaniko's --destination argument:
    - FORMATTEDTAGLIST=$(echo "${FORMATTEDTAGLIST}" | sed s/\-\-tag/\-\-destination/g)

    - BUILD_ARGS="$BUILD_ARGS --build-arg BASE_IMAGE=dahanna/python-alpine-package:alpine-python3-dev-git"
    # For cleanliness, we would prefer to leave build-args *unset* if they are unset here.
    # Thus, we don't want to unconditionally pass --build-arg ETC_ENVIRONMENT_LOCATION=$ETC_ENVIRONMENT_LOCATION,
    # as that would set ETC_ENVIRONMENT_LOCATION to an empty string if ETC_ENVIRONMENT_LOCATION were unset here.
    - if [ -z ${ETC_ENVIRONMENT_LOCATION+ABC} ]; then echo "ETC_ENVIRONMENT_LOCATION is unset, so leaving it unset in the build."; else BUILD_ARGS="$BUILD_ARGS --build-arg ETC_ENVIRONMENT_LOCATION=$ETC_ENVIRONMENT_LOCATION"; fi
    # Currently, kaniko does not support Docker BuildKit --secrets.
    # However, currently, kaniko does not save any --build-arg values in the history.
    # https://github.com/GoogleContainerTools/kaniko/issues/1327
    # But this is not guaranteed to always remain true.
    # For now, until kaniko sorts out how they want to handle secrets,
    # we smuggle in any secrets with a magic variable name that is not stored by either docker build or kaniko.
    # https://docs.docker.com/engine/reference/builder/#predefined-args
    - if [ -z ${SSH_PRIVATE_DEPLOY_KEY+ABC} ]; then echo "SSH_PRIVATE_DEPLOY_KEY is unset, so leaving FTP_PROXY unset in the build."; else BUILD_ARGS="$BUILD_ARGS --build-arg FTP_PROXY=$SSH_PRIVATE_DEPLOY_KEY"; fi

    - echo "FORMATTEDTAGLIST = $FORMATTEDTAGLIST"
    - echo "IMAGE_LABELS = $IMAGE_LABELS"
    - echo "BUILD_ARGS = $BUILD_ARGS"

    - mkdir -p /kaniko/.docker
    - echo "{\"auths\":{\"$CI_REGISTRY\":{\"auth\":\"$(echo -n $CI_REGISTRY_USER:$CI_REGISTRY_PASSWORD | base64)\"}}}" > /kaniko/.docker/config.json
    # --build-arg HTTP_PROXY=$http_proxy is needed for e.g. apk add, when we fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/main/x86_64/APKINDEX.tar.gz
    - /kaniko/executor --context $CI_PROJECT_DIR --dockerfile $CI_PROJECT_DIR/dockerfiles/test.Dockerfile $BUILD_ARGS $FORMATTEDTAGLIST $IMAGE_LABELS


build-for-gitlab-project-registry:
  extends: .build_with_kaniko
  environment:
    #This is only here for completeness; since there are no CI CD Variables with this scope, the project defaults are used
    # to push to this projects docker registry
    name: push-to-gitlab-project-registry

# In general we want to use tox -e docs, but GitLab.com will not deploy Pages
# if the pages build fails.
# The pages build will fail if you use tox -e docs with a link to your GitLab
# Pages documentation that is not yet deployed, because tox -e docs includes
# sphinx-build -b linkcheck. So the pages will never get deployed...
# That's why we deploy pages with no checks here.
# The tests will still run linkcheck on the documentation.
# Since "It may take up to 30 minutes before the site is available after the
# first deployment." (per GitLab), the tests will still fail for a little
# while.
# The magic around GitLab pages is in the name of the job. It has to be named "pages", and nothing else.
pages:
  tags:
  - docker
  stage: build
  # On GitLab, the stages are build->test->deploy.
  # If the test stage fails, the deploy stage is skipped.
{%- if cookiecutter.docs_require_package == 'yes' %}
  # If building the documentation requires your package installed,
  # and building your package takes some time,
  # you might be able to save some time by building a Docker image and using it for both the pages and test jobs.
  # Unfortunately, GitLab does not have a way to specify a primary and fallback image or anything,
  # https://gitlab.com/gitlab-org/gitlab-foss/-/issues/25020
  # so we can't do this automatically.
  # Similarly, we can't hack around this using "only" as we did for the test job,
  # because only one job can have the magic name "pages".
{%- endif %}
  script:
  - pip install -r docs/requirements.txt

  # WordPress rejects uploading these kinds of files, but we can host a simple conda channel on GitLab Pages.
  - ls /bin/sh
  - ls /bin
  - python -c "import sys; print(sys.platform)"
  - if command -v conda; then echo "conda found"; else echo "conda not found"; fi
  - if command -v conda; then
  - if [ "$CONDA_DEFAULT_ENV" = "test-env" ]; then
  # How should we decide whether or not to build a conda package?
  # The thing is that building a conda package takes additional build time,
  # and many people don't use them.
  # For now, the magic env name is what controls it.
  - right_before_conda_build=$(date +%s)
  - conda info
  - apk add bash
  - mkdir docs/_static
  - mkdir docs/_static/conda-channel
  - mkdir docs/_static/conda-channel/linux-64
  # $CONDA_DIR does not contain conda-bld
  # Adding --bootstrap pointed at an environment containing all of the requirements (obtained by conda installing python-nameless and then conda uninstalling python-nameless) does not seem to reduce build time at all.
  # Resource usage summary Total time 0:01:13.5 versus Resource usage summary Total time 0:01:12.3
  - conda build conda.recipe --channel conda-forge --output-folder docs/_static/conda-channel/ --no-test
  - echo "Building the conda package took $(( $(date +%s) - right_before_conda_build)) seconds total"
  - ls docs/_static/conda-channel/
  - ls docs/_static/conda-channel/linux-64/
  - conda convert `ls docs/_static/conda-channel/linux-64/*.tar.bz2` --platform all --output-dir docs/_static/conda-channel/
  # conda index doesn't seem to actually make any additional files beyond what conda build already makes
  - conda index docs/_static/conda-channel/
  - echo "Building the conda channel took $(( $(date +%s) - right_before_conda_build)) seconds total"
    ; else echo "The conda env named test-env is not activated, so not building a conda package."; fi
    ; else
    echo "conda not found in this container, so not building a conda package."
    ; fi

  - sphinx-build -E -b html docs dist/docs

  - if [ -d docs/_static/conda-channel ]; then
  - mv docs/_static/conda-channel dist/docs/_static
    ; fi

  - mv dist/docs/ public/
  - echo "Everything after pulling the Docker image took $(( $(date +%s) - right_after_pull_docker_image)) seconds total"
  artifacts:
    paths:
    - public
  only:
    refs:
      - master
{%- if cookiecutter.docs_require_package == 'no' %}
    changes:
      - docs/**/*
{%- endif %}

test:
  tags:
  - docker
  stage: test
  # https://docs.gitlab.com/ee/ci/yaml/#dependencies
  # By default, all artifacts from all previous stages are passed.
  # And the entire website of a Pages job must be in the artifacts.
  # This can take a nontrivial amount of time, especially if you're hosting a conda package that way,
  # or if the gitlab-runner is pretty far from the GitLab instance server.
  # We want the Pages job to run first because we want to immediately see our changes to the documentation
  # without waiting on the testing to double-check that we don't have any broken links and such.
  # Thus the test job comes after the Pages job, but skips downloading artifacts.
  dependencies: []
  script:
{%- if cookiecutter.docs_require_package == 'no' %}
  # We install the package separately so that we can continuously monitor how long installation takes.
  # Note that pip install . will always reinstall the package even if it is already installed.
  # However, its dependencies will not be reinstalled.
  # If installation nevertheless takes a nontrivial amount of time, and you're building a Docker image anyway,
  # you could skip reinstalling here.
  - right_before_pip_install=$(date +%s)
  - python -m pip install .
  - echo "Installing your package took $(( $(date +%s) - right_before_pip_install)) seconds total"
{%- endif %}
  # If using an image that does not include tox, we will
  # need to pip install tox here.
  - pip install tox

  # apk add any needed packages not included in the image.
  # check-manifest, used in tox -e check, requires git,
  # so we need to either use an image that includes git or
  # apk add git here.

  - git --version || echo "git is not installed."
  - python --version
  - python2 --version || echo "python2 is not installed."
  - virtualenv --version || echo "virtualenv is not installed."
  - pip --version
  - (python -m sphinx --version && python -c "import sphinx; sphinx.version_info < (3,1,2,'final',0) and print('linkcheck can spuriously fail on older versions of Sphinx. If you are seeing anything like 403 Client Error Forbidden, consider upgrading Sphinx.')") || echo "sphinx is not installed."
  - tox --version
  - uname --all
  - lsb_release --all || echo "lsb_release is not supported on this host."
  - start_tox=$(date +%s)
  # When testing locally, we might not want to set sitepackages=true,
  # because the local machine might have all kinds of weird things in the
  # environment. But for continuous integration, we do want sitepackages=true,
  # because it allows us to use a Docker image with some packages already
  # installed to accelerate testing.
  # However, Pygments presents a problem. Lots of Docker images you might want to use
  # have older versions of Pygments that will break your build.
  # (sphinx uses Pygments and so does readme-renderer, used by tox -e check.)
  # pkg_resources.VersionConflict (Pygments 2.4.2 (/opt/conda/envs/test-env/lib/python3.7/site-packages), Requirement.parse('Pygments>=2.5.1'))
  # If an old version of Pygments is installed, we upgrade it first.
  - if python -m pip show Pygments; then python -m pip install --upgrade Pygments; fi
  - tox --sitepackages
  - echo "tox tests took $(( $(date +%s) - start_tox)) seconds"
  - echo "Everything after pulling the Docker image took $(( $(date +%s) - right_after_pull_docker_image)) seconds total"
  only:
    variables:
      - $BUILD_DOCKER_IMAGE == null

test-built-image:
  extends: test
  only:
    variables:
      - $BUILD_DOCKER_IMAGE != null
  image:
    name: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_NAME
    entrypoint: [""]

