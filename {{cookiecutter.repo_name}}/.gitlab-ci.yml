image: dahanna/python.3.7-git-tox-alpine

{% if cookiecutter.ci_https_proxy != "no" -%}
variables:
  # HTTP_PROXY is used to pull docker images.
  HTTP_PROXY: {{cookiecutter.ci_https_proxy}}
  # HTTPS_PROXY is used to install Python packages such as tox.
  HTTPS_PROXY: {{cookiecutter.ci_https_proxy}}
  # If we don't include NO_PROXY, we will get "fatal unable to update url base from redirection"
  # when trying to fetch the gitlab-ci-token.
  NO_PROXY: 127.0.0.1,localhost,.lan,.local,.home,/var/run/docker.sock,{{cookiecutter.repo_hosting_domain}}
{%- endif %}

default:
  before_script:
    - right_after_pull_docker_image=$(date +%s)
    - echo $(whoami)
    - echo $USER
    - if [ -z ${SSH_PRIVATE_KEY+ABC} ]; then echo "SSH_PRIVATE_KEY is unset, so assuming you do not need SSH set up.";
      else
    # All of this will be skipped unless you set SSH_PRIVATE_KEY as a variable at https://{{ cookiecutter.repo_hosting_domain }}/{{ cookiecutter.repo_username }}/{{ cookiecutter.repo_name }}/-/settings/ci_cd
    {% raw -%}
    - if [ ${#SSH_PRIVATE_KEY} -le 5 ]; then echo "SSH_PRIVATE_KEY looks far too short, something is wrong"; fi
    {%- endraw %}
    - apk add openssh-client || apt-get install --assume-yes openssh-client
    - echo "adding openssh-client took $(( $(date +%s) - right_after_pull_docker_image)) seconds"

    # ssh-agent -s starts the ssh-agent and then outputs shell commands to run.
    - eval $(ssh-agent -s)

    ##
    ## Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store.
    ## We're using tr to fix line endings which makes ed25519 keys work
    ## without extra base64 encoding.
    ## We use -d because the version of tr on alpine does not recognize --delete.
    ## https://gitlab.com/gitlab-examples/ssh-private-key/issues/1#note_48526556
    ##
    - echo "$SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -

    ##
    ## Sometimes we may want to install directly from a git repository.
    ## Using up-to-the-minute updates of dependencies in our own tests alerts
    ## us if something breaks with the latest version of a dependency, even if
    ## that dependency has not made a new release yet.
    ## In order to pip install directly from git repositories,
    ## we need to whitelist the public keys of the git servers.
    ## You may want to add more lines for the domains of any other git servers
    ## you want to install dependencies from (which may or may not include the
    ## server that hosts your own repo).
    ## Similarly, if you want to push to a secondary repo as part of your build
    ## (as how cookiecutter-pylibrary builds examples and
    ## pushes to python-nameless), ssh will need to be allowed to reach that
    ## server.
    ##
    - mkdir --parents ~/.ssh
    - ssh-keyscan -t rsa github.com gitlab.com >> ~/.ssh/known_hosts
    - fi

    - if [ -z ${ETC_ENVIRONMENT_LOCATION+ABC} ]; then echo "ETC_ENVIRONMENT_LOCATION is unset, so assuming you do not need environment variables set.";
      else
    # All of this will be skipped unless you set ETC_ENVIRONMENT_LOCATION in GitLab.
    # Strictly speaking, this serves the same function as .profile, being run before everything else.
    # You *could* put arbitrary shell commands in the file, but the intended purpose is
    # to save on manual work by allowing you to set only one GitLab variable that points
    # to more variables to set.
    # Special note if the environment file is used to set up a proxy with HTTPS_PROXY...
    # $ETC_ENVIRONMENT_LOCATION must be a location that we can access *before* setting up the proxy variables.
    - echo $ETC_ENVIRONMENT_LOCATION
    # We do not want the script to hang waiting for a password if the private key is rejected.
    - mkdir --parents ~/.ssh
    - echo "PasswordAuthentication=no" >> ~/.ssh/config
    - echo $SSH_PRIVATE_KEY > SSH.PRIVATE.KEY # If SSH_PRIVATE_KEY is unset, this will just be empty.
    - wget $ETC_ENVIRONMENT_LOCATION --output-document environment.sh --no-clobber || scp -i SSH.PRIVATE.KEY $ETC_ENVIRONMENT_LOCATION environment.sh
    - rm SSH.PRIVATE.KEY
    - cat environment.sh
    - set -o allexport
    - source environment.sh
    - set +o allexport
    - fi

    # We might potentially need SSH set up before we go get the environment file.
    # But after we get the environment file, it might have some servers for us to whitelist.
    # Alternatively, maybe there was no ETC_ENVIRONMENT_LOCATION
    # and SERVERS_TO_WHITELIST_FOR_SSH is just manually set as a GitLab variable.
    - if [ -z ${SERVERS_TO_WHITELIST_FOR_SSH+ABC} ]; then echo "SERVERS_TO_WHITELIST_FOR_SSH is unset, so assuming you do not need any servers whitelisted for SSH.";
      else
    - echo $SERVERS_TO_WHITELIST_FOR_SSH
    - mkdir --parents ~/.ssh
    # This may crash if SSH_PRIVATE_KEY was not set so we didn't install openssh-client.
    # If SERVERS_TO_WHITELIST_FOR_SSH is set but SSH_PRIVATE_KEY is not, clearly something is very wrong.
    - ssh-keyscan -t rsa $SERVERS_TO_WHITELIST_FOR_SSH >> ~/.ssh/known_hosts
    - fi

    - pip install --upgrade pip
    - if [ -z ${PROXY_CA_PEM+ABC} ]; then echo "PROXY_CA_PEM is unset, so assuming you do not need a merged CA certificate set up.";
      else
    # All of this will be skipped unless you set PROXY_CA_PEM in GitLab.
    # You will usually want to cat your.pem | xclip and paste it in as a File on GitLab.
    # See the KUBE_CA_PEM example at https://docs.gitlab.com/ee/ci/variables/README.html#variable-types
    - right_before_pull_cert=$(date +%s)
    {% raw -%}
    - if [ ${#PROXY_CA_PEM} -ge 1024 ]; then
    {%- endraw %}
    - echo "The PROXY_CA_PEM filename looks far too long, did you set it as a Variable instead of a File?"
    # If it's the full certificate rather than a filename, write it to a file and save the file name.
    - echo $PROXY_CA_PEM > tmp.pem
    - PROXY_CA_PEM=tmp.pem
      ; fi
    # If some of the links in your documentation require a special PEM to verify,
    # then sphinx -b linkcheck will fail without that PEM.
    # But setting REQUESTS_CA_BUNDLE to that PEM will cause other links to fail,
    # because the runner will only accept that PEM, not the defaults.
    # Therefore you will usually want to bundle all certificates together with
    # cat `python -c "import requests; print(requests.certs.where())"` ~/your.pem > ~/bundled.pem
    # pip uses requests, but not the normal requests.
    # pip uses a vendored version of requests, so that pip will still work if anything goes wrong with your requests installation.
    # We find where that vendored version of requests keeps its certs and merge in the cert from PROXY_CA_PEM.
    # On some systems, we might need to try the import twice, and the first time, it will fail with an AttributeError.
    # Therefore we need a block to suppress the AttributeError, which requires a colon.
    # But that causes parsing of .gitlab-ci.yml to fail with "before_script config should be an array of strings",
    # so we need to wrap the entire line in ''.
    # https://gitlab.com/gitlab-org/gitlab-foss/merge_requests/5481
    - 'echo -e "import contextlib\nwith contextlib.suppress(AttributeError): import pip._vendor.requests\nfrom pip._vendor.requests.certs import where\nprint(where())" | python'
    - 'cat `echo -e "import contextlib\nwith contextlib.suppress(AttributeError): import pip._vendor.requests\nfrom pip._vendor.requests.certs import where\nprint(where())" | python` $PROXY_CA_PEM > bundled.pem'
    - export REQUESTS_CA_BUNDLE=bundled.pem
    - echo "Merging the certificate bundle took $(( $(date +%s) - right_before_pull_cert)) seconds total"
    - fi

    ##
    ## With all our proxy variables and certificates in place, we should now be
    ## able to install from repositores, and optionally push to repositories.
    ## Optionally, if you will be making any git commits, set the user name and
    ## email.
    ##
    #- git config --global user.email "{{ cookiecutter.email }}"
    #- git config --global user.name "{{ cookiecutter.full_name }}"

# In general we want to use tox -e docs, but GitLab.com will not deploy Pages
# if the pages build fails.
# The pages build will fail if you use tox -e docs with a link to your GitLab
# Pages documentation that is not yet deployed, because tox -e docs includes
# sphinx-build -b linkcheck. So the pages will never get deployed...
# That's why we deploy pages with no checks here.
# The tests will still run linkcheck on the documentation.
# Since "It may take up to 30 minutes before the site is available after the
# first deployment." (per GitLab), the tests will still fail for a little
# while.
pages:
  tags:
  - docker
  stage: build
  # On GitLab, the stages are build->test->deploy.
  # If the test stage fails, the deploy stage is skipped.
  script:
  - pip install -r docs/requirements.txt
  - sphinx-build -E -b html docs dist/docs
  - mv dist/docs/ public/
  artifacts:
    paths:
    - public
  only:
  - master

test:
  tags:
  - docker
  stage: test
  script:
  # apk add any needed packages not included in the image.
  # check-manifest, used in tox -e check, requires git,
  # so we need to either use an image that includes git or
  # apk add git here.
  # If using an image that does not include tox, we will
  # need to pip install tox here.
  # With --sitepackages, we can save time by installing once
  # for both regular tests and documentation checks.
  - pip install .
  - git --version
  - python --version
  - python2 --version || echo "python2 is not installed."
  - virtualenv --version
  - pip --version
  - tox --version
  - uname --all
  - lsb_release --all || echo "lsb_release is not supported on this host."
  - start_tox=$(date +%s)
  # When testing locally, we might not want to set sitepackages=true,
  # because the local machine might have all kinds of weird things in the
  # environment. But for continuous integration, we do want sitepackages=true,
  # because it allows us to use a Docker image with some packages already
  # installed to accelerate testing.
  - tox --sitepackages
  - echo "tox tests took $(( $(date +%s) - start_tox)) seconds"
  - echo "Everything after pulling the Docker image took $(( $(date +%s) - right_after_pull_docker_image)) seconds total"

